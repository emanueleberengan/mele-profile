{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Intro: Loading GPT‑2 Variants & What the Config Knobs Change\n",
    "\n",
    "This notebook downloads OpenAI’s GPT‑2 weights and loads them into a compatible PyTorch model to generate text.  \n",
    "You can switch among GPT‑2 sizes (Small/Medium/Large/XL) by changing the **model configuration** you pass to `GPTModel` and by downloading the matching **pretrained weights**.\n",
    "\n",
    "Below is a quick guide to what each config field does, how it affects **downloading weights** and **text generation**, and a few practical tips.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 13:24:52.865139: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-28 13:24:52.911148: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-28 13:24:54.078871: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/774M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/774M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/774M/vocab.bpe\n",
      "Settings {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 1280, 'n_head': 20, 'n_layer': 36}\n",
      "Params keys dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from gpt2 import GPT_CONFIG_124M, GPTModel, text_to_token_ids, generate_t_k, token_ids_to_text\n",
    "import torch, tiktoken\n",
    "import numpy as np\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "print(\"Settings\", settings)\n",
    "print(\"Params keys\",params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer from Tensorflow to GPT implementation Q, K and V including Bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.token_emb.weight = assign(gpt.token_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": { \"emb_dim\" : 768, \"n_layers\" : 12, \"n_heads\" : 12},\n",
    "    \"gpt2-medium (355M)\" : {\"emb_dim\" : 1024, \"n_layers\" : 24, \"n_heads\" : 16},\n",
    "    \"gpt2-large (774M)\" : {\"emb_dim\" : 1280, \"n_layers\" : 36, \"n_heads\" : 20},\n",
    "    \"gpt2-xl (1558M)\" : {\"emb_dim\" : 1600, \"n_layers\" : 48, \"n_heads\" : 25}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The `model_configs` knobs (and what they impact)\n",
    "\n",
    "- **`emb_dim` (hidden size)**\n",
    "  - **What it is:** Width of token/hidden representations.\n",
    "  - **Download impact:** Must match the width of the downloaded checkpoint. If it doesn’t, weight loading will fail due to shape mismatches.\n",
    "  - **Generation impact:** Larger = typically better fluency/knowledge, but more GPU/CPU memory and slower inference.\n",
    "\n",
    "- **`n_layers` (number of transformer blocks)**\n",
    "  - **What it is:** Depth of the model (stacked transformer blocks).\n",
    "  - **Download impact:** Must match the checkpoint’s depth; otherwise weights won’t align with your model’s layers.\n",
    "  - **Generation impact:** Deeper = generally better quality/longer-range reasoning, but slower and more memory‑hungry.\n",
    "\n",
    "- **`n_heads` (attention heads per layer)**\n",
    "  - **What it is:** Parallel attention subspaces; must evenly divide `emb_dim`.\n",
    "  - **Download impact:** Must match the checkpoint; mismatches cause shape errors when splitting/merging Q/K/V projections.\n",
    "  - **Generation impact:** More heads (with matching `emb_dim`) improve attention expressivity; compute cost grows accordingly.\n",
    "\n",
    "- **`context_length` (a.k.a. sequence length / block size)**\n",
    "  - **What it is:** Maximum tokens the model attends to at once.\n",
    "  - **Download impact:** Checkpoints are trained for a certain context window (GPT‑2 was trained for 1024). You can **set a larger number**, but the weights aren’t trained for it—generation beyond the trained window may degrade.\n",
    "  - **Generation impact:** Higher = can consider longer prompts but uses more memory and can slow down attention quadratically with sequence length.\n",
    "\n",
    "- **`qkv_bias` (bias terms in Q/K/V projections)**\n",
    "  - **What it is:** Whether linear projections for Q/K/V include bias parameters.\n",
    "  - **Download impact:** Must match the original architecture of the checkpoint. If the checkpoint has no bias but your model expects it (or vice versa), shapes won’t match.\n",
    "  - **Generation impact:** Minor quality/speed effect compared to other knobs; mainly matters for weight compatibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW_CONFIG {'vocab_size': 50257, 'context_length': 1024, 'emb_dim': 1280, 'n_heads': 20, 'n_layers': 36, 'drop_rate': 0.1, 'qkv_bias': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 1280)\n",
       "  (pos_emb): Embedding(1024, 1280)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2-large (774M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\":1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\":True})\n",
    "\n",
    "print(\"NEW_CONFIG\",NEW_CONFIG)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()\n",
    "\n",
    "load_weights_into_gpt(gpt,params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Practical trade‑offs\n",
    "\n",
    "- **Quality vs. speed/memory**\n",
    "  - **Small (124M)**: Fastest, least memory, good for quick tests.\n",
    "  - **Medium/Large/XL**: Better generations, but progressively heavier and slower.\n",
    "- **Context window**\n",
    "  - Keep `context_length = 1024` for faithful GPT‑2 behavior. Larger values are possible but not trained, may degrade beyond 1024 tokens and will increase compute.\n",
    "- **Sampling controls**\n",
    "  - `temperature` and `top_k` shape the creativity and diversity of outputs:\n",
    "    - Higher `temperature` → more diverse/creative (riskier).\n",
    "    - Lower `top_k` → safer/more focused; higher → more variety.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text gpt2 style: \n",
      "\n",
      " ### Instruction:\n",
      " Convert 5 cm to meters.\n",
      "The conversion is done using the following formula:\n",
      "M = (5/4) x (5/3) x (5/2)\n",
      "Where M is the length of the string, 5 cm is the string's diameter, and 4\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(123)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_t_k(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"### Instruction:\\n Convert 5 cm to meters.\",tokenizer=tokenizer).to(device),\n",
    "    max_new_tokens=50,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=3,\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "print(\"Generated text gpt2 style: \\n\\n\", token_ids_to_text(token_ids=token_ids,tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare a dataset for fine tuning the model for instructions in Aplaca promt style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries: 1100\n",
      "Example data\n",
      " {'instruction': \"What is the plural form of 'mouse'?\", 'input': '', 'output': \"The plural form of 'mouse' is 'mice'.\"}\n",
      "\n",
      "Below is an instruction that describe a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using an idiom.\n",
      "\n",
      "### Input:\n",
      "The storm started suddenly.\n",
      "\n",
      "### Response:\n",
      "The storm came out of the blue.\n"
     ]
    }
   ],
   "source": [
    "import json, os, urllib\n",
    "import urllib.request\n",
    "\n",
    "def download_and_load_finet(file_path,url):\n",
    "    if (not os.path.exists(file_path)):\n",
    "        with urllib.request.urlopen(url,timeout=1000) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "            \n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"gpt2/instructions-data.json\"\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "\n",
    "data = download_and_load_finet(file_path=file_path,url=url)\n",
    "print (\"number of entries:\", len(data))\n",
    "\n",
    "print(\"Example data\\n\",data[25])\n",
    "\n",
    "def format_alpa_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describe a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
    "    )\n",
    "    \n",
    "    return instruction_text + input_text\n",
    "\n",
    "## Now test the completion of input and output with\n",
    "index = 22\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[index]['output']}\"\n",
    "print(\"\\n\" + format_alpa_input(data[index]) + desired_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in train, test and validate portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set lenght:  935\n",
      "Test set lenght:  110\n",
      "Validation set lenght:  55\n"
     ]
    }
   ],
   "source": [
    "train_p = int(len(data) * .85)\n",
    "test_p = int (len(data) * .1)\n",
    "val_p = len(data)- train_p - test_p\n",
    "\n",
    "train_d = data[:train_p]\n",
    "test_d = data[train_p:train_p+test_p]\n",
    "val_d = data[train_p + test_p:]\n",
    "\n",
    "print(\"Training set lenght: \", len(train_d))\n",
    "print(\"Test set lenght: \", len(test_d))\n",
    "print(\"Validation set lenght: \", len(val_d))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To iport the data set it's required to prepare data to be tokenized and well batched having same shape for train and target. So considering that each entry is having different length we need to override the standard collate function of Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_text = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_alpa_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{data[index]['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_text.append(tokenizer.encode(full_text))\n",
    "            \n",
    "    def __getitem__ (self,index):\n",
    "        return self.encoded_text[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.data))\n",
    "    \n",
    "def custom_collate_fn(\n",
    "    batch,                #already tokenized batch to pad and prepare for target and input\n",
    "    pad_token_id = 50256, #last token of gpt2 <|end-of-text|>\n",
    "    ignore_index = -100,  #index ignored by code in cross entropy for loss calculation\n",
    "    allowed_max_length = None,\n",
    "    device = \"cpu\"\n",
    "):\n",
    "    batch_max_length = max (len(item) + 1 for item in batch) #calculate the max length of all the entry in the batch\n",
    "    input_lst, target_lst = [], []  # this will be he returned tensors output\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id] # addin terminator string\n",
    "        \n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * ( batch_max_length - len(new_item))\n",
    "        ) # and padding the \n",
    "        \n",
    "        inputs = torch.tensor(padded[:-1]) # truncate the last token for input\n",
    "        targets = torch.tensor(padded[1:]) # shift + 1 the right for targets\n",
    "        \n",
    "        # masking the target eos with -100\n",
    "        mask = targets == pad_token_id              # creating a mask of index to assing -100 to all eos\n",
    "        indices = torch.nonzero(mask).squeeze()     # getting  out the index of wethere there is a need to mask\n",
    "        if indices.numel() > 1 :\n",
    "            targets[indices[1:]] = ignore_index     # assigning -100 to the index that's having padding\n",
    "            \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "            \n",
    "        input_lst.append(inputs)\n",
    "        target_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(input_lst).to(device)\n",
    "    targets_tensor = torch.stack(target_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working now on the Dataloader to build the dataset required for the finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 52]) torch.Size([4, 52])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 49]) torch.Size([4, 49])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 55]) torch.Size([4, 55])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 66]) torch.Size([4, 66])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 66]) torch.Size([4, 66])\n",
      "torch.Size([4, 68]) torch.Size([4, 68])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 57]) torch.Size([4, 57])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 48]) torch.Size([4, 48])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 47]) torch.Size([4, 47])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 51]) torch.Size([4, 51])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 56]) torch.Size([4, 56])\n",
      "torch.Size([4, 57]) torch.Size([4, 57])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 68]) torch.Size([4, 68])\n",
      "torch.Size([4, 49]) torch.Size([4, 49])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 51]) torch.Size([4, 51])\n",
      "torch.Size([4, 56]) torch.Size([4, 56])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 51]) torch.Size([4, 51])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 67]) torch.Size([4, 67])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 67]) torch.Size([4, 67])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 67]) torch.Size([4, 67])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 66]) torch.Size([4, 66])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 48]) torch.Size([4, 48])\n",
      "torch.Size([4, 57]) torch.Size([4, 57])\n",
      "torch.Size([4, 48]) torch.Size([4, 48])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 49]) torch.Size([4, 49])\n",
      "torch.Size([4, 51]) torch.Size([4, 51])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 49]) torch.Size([4, 49])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 66]) torch.Size([4, 66])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 51]) torch.Size([4, 51])\n",
      "torch.Size([4, 73]) torch.Size([4, 73])\n",
      "torch.Size([4, 57]) torch.Size([4, 57])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 54]) torch.Size([4, 54])\n",
      "torch.Size([4, 70]) torch.Size([4, 70])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 57]) torch.Size([4, 57])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 67]) torch.Size([4, 67])\n",
      "torch.Size([4, 73]) torch.Size([4, 73])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 51]) torch.Size([4, 51])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 57]) torch.Size([4, 57])\n",
      "torch.Size([4, 55]) torch.Size([4, 55])\n",
      "torch.Size([4, 55]) torch.Size([4, 55])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 49]) torch.Size([4, 49])\n",
      "torch.Size([4, 66]) torch.Size([4, 66])\n",
      "torch.Size([4, 67]) torch.Size([4, 67])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 68]) torch.Size([4, 68])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 53]) torch.Size([4, 53])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 72]) torch.Size([4, 72])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 48]) torch.Size([4, 48])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 53]) torch.Size([4, 53])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 54]) torch.Size([4, 54])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 48]) torch.Size([4, 48])\n",
      "torch.Size([4, 55]) torch.Size([4, 55])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 55]) torch.Size([4, 55])\n",
      "torch.Size([4, 54]) torch.Size([4, 54])\n",
      "torch.Size([4, 49]) torch.Size([4, 49])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 66]) torch.Size([4, 66])\n",
      "torch.Size([4, 56]) torch.Size([4, 56])\n",
      "torch.Size([4, 49]) torch.Size([4, 49])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 49]) torch.Size([4, 49])\n",
      "torch.Size([4, 56]) torch.Size([4, 56])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 57]) torch.Size([4, 57])\n",
      "torch.Size([4, 53]) torch.Size([4, 53])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 69]) torch.Size([4, 69])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 71]) torch.Size([4, 71])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 55]) torch.Size([4, 55])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 66]) torch.Size([4, 66])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 49]) torch.Size([4, 49])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 56]) torch.Size([4, 56])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 55]) torch.Size([4, 55])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 48]) torch.Size([4, 48])\n",
      "torch.Size([4, 50]) torch.Size([4, 50])\n",
      "torch.Size([4, 73]) torch.Size([4, 73])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 70]) torch.Size([4, 70])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n",
      "torch.Size([4, 52]) torch.Size([4, 52])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 55]) torch.Size([4, 55])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 51]) torch.Size([4, 51])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 53]) torch.Size([4, 53])\n",
      "torch.Size([4, 51]) torch.Size([4, 51])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 67]) torch.Size([4, 67])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 70]) torch.Size([4, 70])\n",
      "torch.Size([4, 63]) torch.Size([4, 63])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 60]) torch.Size([4, 60])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 64]) torch.Size([4, 64])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 61]) torch.Size([4, 61])\n",
      "torch.Size([4, 58]) torch.Size([4, 58])\n",
      "torch.Size([4, 59]) torch.Size([4, 59])\n",
      "torch.Size([4, 62]) torch.Size([4, 62])\n",
      "torch.Size([4, 65]) torch.Size([4, 65])\n"
     ]
    }
   ],
   "source": [
    "num_workers = 4 \n",
    "batch_size = 4\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_d,tokenizer=tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn = custom_collate_fn,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_d,tokenizer=tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn = custom_collate_fn,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_d,tokenizer=tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn = custom_collate_fn,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# print the data to confirm that input and target batches have always the same length\n",
    "\n",
    "for inputs,targets in train_loader:\n",
    "    print(inputs.shape,targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time now to fine tune the model with the provided datase but before we want to get an estimation of the current loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss prior instruct:  4.092750024795532\n",
      "Validation loss prior instruct:  4.067868328094482\n"
     ]
    }
   ],
   "source": [
    "from gpt2 import calc_loss_dataloaders, train_model_simple\n",
    "\n",
    "gpt.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_dataloaders(\n",
    "        data_loader=train_loader,\n",
    "        model=gpt,\n",
    "        device=device,\n",
    "        num_batches=5\n",
    "    )\n",
    "    \n",
    "    val_loss = calc_loss_dataloaders(\n",
    "        data_loader=val_loader,\n",
    "        model=gpt,\n",
    "        device=device,\n",
    "        num_batches=5\n",
    "    )\n",
    "\n",
    "print (\"Training loss prior instruct: \", train_loss)\n",
    "print (\"Validation loss prior instruct: \", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to minimize the loss let's try to do it and to measure the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 15.64 GiB of which 2.88 MiB is free. Including non-PyTorch memory, this process has 15.62 GiB memory in use. Of the allocated memory 15.02 GiB is allocated by PyTorch, and 539.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(\n\u001b[1;32m      8\u001b[0m     gpt\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m      9\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00005\u001b[39m,\n\u001b[1;32m     10\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m num_epocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 15\u001b[0m train_losses, val_losses, tokens_seen \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_alpa_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_d\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     22\u001b[0m execution_time_minutes \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "File \u001b[0;32m~/mele-profile/mele-profile/GPT/5 - ClassificationFT/gpt2.py:307\u001b[0m, in \u001b[0;36mtrain_model_simple\u001b[0;34m(model, train_loader, test_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[1;32m    301\u001b[0m loss \u001b[38;5;241m=\u001b[39m calc_loss_batch(\n\u001b[1;32m    302\u001b[0m     input_batch,target_batch,model, device\n\u001b[1;32m    303\u001b[0m     \n\u001b[1;32m    304\u001b[0m )\n\u001b[1;32m    306\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 307\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m token_seen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m input_batch\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;66;03m# + one more in the stack of seen tokens\u001b[39;00m\n\u001b[1;32m    310\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/mele-profile/mele-profile/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:526\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    522\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    523\u001b[0m             )\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# pyrefly: ignore [invalid-param-spec]\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/mele-profile/mele-profile/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:81\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     80\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 81\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/mele-profile/mele-profile/venv/lib/python3.10/site-packages/torch/optim/adam.py:248\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    236\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    238\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    239\u001b[0m         group,\n\u001b[1;32m    240\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m         state_steps,\n\u001b[1;32m    246\u001b[0m     )\n\u001b[0;32m--> 248\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/mele-profile/mele-profile/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:151\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mele-profile/mele-profile/venv/lib/python3.10/site-packages/torch/optim/adam.py:970\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    968\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 970\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mele-profile/mele-profile/venv/lib/python3.10/site-packages/torch/optim/adam.py:791\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    789\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 791\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m    794\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 15.64 GiB of which 2.88 MiB is free. Including non-PyTorch memory, this process has 15.62 GiB memory in use. Of the allocated memory 15.02 GiB is allocated by PyTorch, and 539.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    gpt.parameters(),\n",
    "    lr=0.00005,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "\n",
    "num_epocs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    gpt, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epocs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_alpa_input(val_d[0]),tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
