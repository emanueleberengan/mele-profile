{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Intro: Loading GPT‑2 Variants & What the Config Knobs Change\n",
    "\n",
    "This notebook downloads OpenAI’s GPT‑2 weights and loads them into a compatible PyTorch model to generate text.  \n",
    "You can switch among GPT‑2 sizes (Small/Medium/Large/XL) by changing the **model configuration** you pass to `GPTModel` and by downloading the matching **pretrained weights**.\n",
    "\n",
    "Below is a quick guide to what each config field does, how it affects **downloading weights** and **text generation**, and a few practical tips.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n",
      "Settings {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Params keys dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from gpt2 import GPT_CONFIG_124M, GPTModel, text_to_token_ids, generate_t_k, token_ids_to_text\n",
    "import torch, tiktoken\n",
    "import numpy as np\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "print(\"Settings\", settings)\n",
    "print(\"Params keys\",params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer from Tensorflow to GPT implementation Q, K and V including Bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.token_emb.weight = assign(gpt.token_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": { \"emb_dim\" : 768, \"n_layers\" : 12, \"n_heads\" : 12},\n",
    "    \"gpt2-medium (355M)\" : {\"emb_dim\" : 1024, \"n_layers\" : 24, \"n_heads\" : 16},\n",
    "    \"gpt2-large (774M)\" : {\"emb_dim\" : 1280, \"n_layers\" : 36, \"n_heads\" : 20},\n",
    "    \"gpt2-xl (1558M)\" : {\"emb_dim\" : 1600, \"n_layers\" : 48, \"n_heads\" : 25}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The `model_configs` knobs (and what they impact)\n",
    "\n",
    "- **`emb_dim` (hidden size)**\n",
    "  - **What it is:** Width of token/hidden representations.\n",
    "  - **Download impact:** Must match the width of the downloaded checkpoint. If it doesn’t, weight loading will fail due to shape mismatches.\n",
    "  - **Generation impact:** Larger = typically better fluency/knowledge, but more GPU/CPU memory and slower inference.\n",
    "\n",
    "- **`n_layers` (number of transformer blocks)**\n",
    "  - **What it is:** Depth of the model (stacked transformer blocks).\n",
    "  - **Download impact:** Must match the checkpoint’s depth; otherwise weights won’t align with your model’s layers.\n",
    "  - **Generation impact:** Deeper = generally better quality/longer-range reasoning, but slower and more memory‑hungry.\n",
    "\n",
    "- **`n_heads` (attention heads per layer)**\n",
    "  - **What it is:** Parallel attention subspaces; must evenly divide `emb_dim`.\n",
    "  - **Download impact:** Must match the checkpoint; mismatches cause shape errors when splitting/merging Q/K/V projections.\n",
    "  - **Generation impact:** More heads (with matching `emb_dim`) improve attention expressivity; compute cost grows accordingly.\n",
    "\n",
    "- **`context_length` (a.k.a. sequence length / block size)**\n",
    "  - **What it is:** Maximum tokens the model attends to at once.\n",
    "  - **Download impact:** Checkpoints are trained for a certain context window (GPT‑2 was trained for 1024). You can **set a larger number**, but the weights aren’t trained for it—generation beyond the trained window may degrade.\n",
    "  - **Generation impact:** Higher = can consider longer prompts but uses more memory and can slow down attention quadratically with sequence length.\n",
    "\n",
    "- **`qkv_bias` (bias terms in Q/K/V projections)**\n",
    "  - **What it is:** Whether linear projections for Q/K/V include bias parameters.\n",
    "  - **Download impact:** Must match the original architecture of the checkpoint. If the checkpoint has no bias but your model expects it (or vice versa), shapes won’t match.\n",
    "  - **Generation impact:** Minor quality/speed effect compared to other knobs; mainly matters for weight compatibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW_CONFIG {'vocab_size': 50257, 'context_length': 1024, 'emb_dim': 768, 'n_heads': 12, 'n_layers': 12, 'drop_rate': 0.1, 'qkv_bias': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\":1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\":True})\n",
    "\n",
    "print(\"NEW_CONFIG\",NEW_CONFIG)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()\n",
    "\n",
    "load_weights_into_gpt(gpt,params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Practical trade‑offs\n",
    "\n",
    "- **Quality vs. speed/memory**\n",
    "  - **Small (124M)**: Fastest, least memory, good for quick tests.\n",
    "  - **Medium/Large/XL**: Better generations, but progressively heavier and slower.\n",
    "- **Context window**\n",
    "  - Keep `context_length = 1024` for faithful GPT‑2 behavior. Larger values are possible but not trained, may degrade beyond 1024 tokens and will increase compute.\n",
    "- **Sampling controls**\n",
    "  - `temperature` and `top_k` shape the creativity and diversity of outputs:\n",
    "    - Higher `temperature` → more diverse/creative (riskier).\n",
    "    - Lower `top_k` → safer/more focused; higher → more variety.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text gpt2 style: \n",
      "\n",
      " ### Instruction:\n",
      " Convert 5 cm to meters.\n",
      "\n",
      "### Instruction:\n",
      "Generate a random sequence of 3 digits.\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'<|endoftext|>The following is an instruction that describe a task. Write a response that appropriately completes the request.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(123)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_t_k(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"### Instruction:\\n Convert 5 cm to meters.\",tokenizer=tokenizer).to(device),\n",
    "    max_new_tokens=50,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=3,\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "print(\"Generated text gpt2 style: \\n\\n\", token_ids_to_text(token_ids=token_ids,tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare a dataset for fine tuning the model for instructions in Aplaca promt style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries: 1100\n",
      "Example data\n",
      " {'instruction': \"What is the plural form of 'mouse'?\", 'input': '', 'output': \"The plural form of 'mouse' is 'mice'.\"}\n",
      "\n",
      "Below is an instruction that describe a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using an idiom.\n",
      "\n",
      "### Input:\n",
      "The storm started suddenly.\n",
      "\n",
      "### Response:\n",
      "The storm came out of the blue.\n"
     ]
    }
   ],
   "source": [
    "import json, os, urllib\n",
    "import urllib.request\n",
    "\n",
    "def download_and_load_finet(file_path,url):\n",
    "    if (not os.path.exists(file_path)):\n",
    "        with urllib.request.urlopen(url,timeout=1000) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "            \n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"gpt2/instructions-data.json\"\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "\n",
    "data = download_and_load_finet(file_path=file_path,url=url)\n",
    "print (\"number of entries:\", len(data))\n",
    "\n",
    "print(\"Example data\\n\",data[25])\n",
    "\n",
    "def format_alpa_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describe a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
    "    )\n",
    "    \n",
    "    return instruction_text + input_text\n",
    "\n",
    "## Now test the completion of input and output with\n",
    "index = 22\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[index]['output']}\"\n",
    "print(\"\\n\" + format_alpa_input(data[index]) + desired_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in train, test and validate portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set lenght:  935\n",
      "Test set lenght:  110\n",
      "Validation set lenght:  55\n"
     ]
    }
   ],
   "source": [
    "train_p = int(len(data) * .85)\n",
    "test_p = int (len(data) * .1)\n",
    "val_p = len(data)- train_p - test_p\n",
    "\n",
    "train_d = data[:train_p]\n",
    "test_d = data[train_p:train_p+test_p]\n",
    "val_d = data[train_p + test_p:]\n",
    "\n",
    "print(\"Training set lenght: \", len(train_d))\n",
    "print(\"Test set lenght: \", len(test_d))\n",
    "print(\"Validation set lenght: \", len(val_d))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To iport the data set it's required to prepare data to be tokenized and well batched having same shape for train and target. So considering that each entry is having different length we need to override the standard collate function of Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_text = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_alpa_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{data[index]['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_text.append(tokenizer.encode(full_text))\n",
    "            \n",
    "    def __getitem__ (self,index):\n",
    "        return self.encoded_text[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.data))\n",
    "    \n",
    "def custom_collate_fn(\n",
    "    batch,                #already tokenized batch to pad and prepare for target and input\n",
    "    pad_token_id = 50256, #last token of gpt2 <|end-of-text|>\n",
    "    ignore_index = -100,  #index ignored by code in cross entropy for loss calculation\n",
    "    allowed_max_length = None,\n",
    "    device = \"cpu\"\n",
    "):\n",
    "    batch_max_length = max (len(item) + 1 for item in batch) #calculate the max length of all the entry in the batch\n",
    "    input_lst, target_lst = [], []  # this will be he returned tensors output\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id] # addin terminator string\n",
    "        \n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * ( batch_max_length - len(new_item))\n",
    "        ) # and padding the \n",
    "        \n",
    "        inputs = torch.tensor(padded[:-1]) # truncate the last token for input\n",
    "        targets = torch.tensor(padded[1:]) # shift + 1 the right for targets\n",
    "        \n",
    "        # masking the target eos with -100\n",
    "        mask = targets == pad_token_id              # creating a mask of index to assing -100 to all eos\n",
    "        indices = torch.nonzero(mask).squeeze()     # getting  out the index of wethere there is a need to mask\n",
    "        if indices.numel() > 1 :\n",
    "            targets[indices[1:]] = ignore_index     # assigning -100 to the index that's having padding\n",
    "            \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "            \n",
    "        input_lst.append(inputs)\n",
    "        target_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(input_lst).to(device)\n",
    "    targets_tensor = torch.stack(target_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working now on the Dataloader to build the dataset required for the finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n"
     ]
    }
   ],
   "source": [
    "num_workers = 0 \n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_d,tokenizer=tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn = custom_collate_fn,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_d,tokenizer=tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn = custom_collate_fn,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_d,tokenizer=tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn = custom_collate_fn,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# print the data to confirm that input and target batches have always the same length\n",
    "\n",
    "for inputs,targets in train_loader:\n",
    "    print(inputs.shape,targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time now to fine tune the model with the provided datase but before we want to get an estimation of the current loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss prior instruct:  4.729192543029785\n",
      "Validation loss prior instruct:  4.855866146087647\n"
     ]
    }
   ],
   "source": [
    "from gpt2 import calc_loss_dataloaders, train_model_simple\n",
    "\n",
    "gpt.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_dataloaders(\n",
    "        data_loader=train_loader,\n",
    "        model=gpt,\n",
    "        device=device,\n",
    "        num_batches=5\n",
    "    )\n",
    "    \n",
    "    val_loss = calc_loss_dataloaders(\n",
    "        data_loader=val_loader,\n",
    "        model=gpt,\n",
    "        device=device,\n",
    "        num_batches=5\n",
    "    )\n",
    "\n",
    "print (\"Training loss prior instruct: \", train_loss)\n",
    "print (\"Validation loss prior instruct: \", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to minimize the loss let's try to do it and to measure the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step: 000000): Train loss 3.730, Test loss 3.789\n",
      "Ep 1 (Step: 000005): Train loss 1.900, Test loss 2.100\n",
      "Ep 1 (Step: 000010): Train loss 1.125, Test loss 1.521\n",
      "Ep 1 (Step: 000015): Train loss 0.886, Test loss 1.489\n",
      "Ep 1 (Step: 000020): Train loss 0.770, Test loss 1.295\n",
      "Ep 1 (Step: 000025): Train loss 0.690, Test loss 1.303\n",
      "Ep 1 (Step: 000030): Train loss 0.655, Test loss 1.287\n",
      "Ep 1 (Step: 000035): Train loss 0.550, Test loss 1.273\n",
      "Ep 1 (Step: 000040): Train loss 0.553, Test loss 1.264\n",
      "Ep 1 (Step: 000045): Train loss 0.590, Test loss 1.317\n",
      "Ep 1 (Step: 000050): Train loss 0.603, Test loss 1.286\n",
      "Ep 1 (Step: 000055): Train loss 0.634, Test loss 1.241\n",
      "Ep 1 (Step: 000060): Train loss 0.524, Test loss 1.306\n",
      "Ep 1 (Step: 000065): Train loss 0.578, Test loss 1.283\n",
      "Ep 1 (Step: 000070): Train loss 0.495, Test loss 1.218\n",
      "Ep 1 (Step: 000075): Train loss 0.598, Test loss 1.243\n",
      "Ep 1 (Step: 000080): Train loss 0.470, Test loss 1.227\n",
      "Ep 1 (Step: 000085): Train loss 0.539, Test loss 1.227\n",
      "Ep 1 (Step: 000090): Train loss 0.544, Test loss 1.212\n",
      "Ep 1 (Step: 000095): Train loss 0.450, Test loss 1.213\n",
      "Ep 1 (Step: 000100): Train loss 0.422, Test loss 1.162\n",
      "Ep 1 (Step: 000105): Train loss 0.393, Test loss 1.174\n",
      "Ep 1 (Step: 000110): Train loss 0.475, Test loss 1.146\n",
      "Ep 1 (Step: 000115): Train loss 0.412, Test loss 1.099\n",
      "decoded text:  Below is an instruction that describe a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The correct spelling is 'Occasion.'<|endoftext|>The following is an instruction that describe a task. Write a response that appropriately completes the request.  ### Input: The correct spelling is 'Occasion.'<|endoftext|>The\n",
      "Ep 2 (Step: 000120): Train loss 0.498, Test loss 1.130\n",
      "Ep 2 (Step: 000125): Train loss 0.403, Test loss 1.078\n",
      "Ep 2 (Step: 000130): Train loss 0.435, Test loss 1.113\n",
      "Ep 2 (Step: 000135): Train loss 0.419, Test loss 1.139\n",
      "Ep 2 (Step: 000140): Train loss 0.374, Test loss 1.115\n",
      "Ep 2 (Step: 000145): Train loss 0.398, Test loss 1.133\n",
      "Ep 2 (Step: 000150): Train loss 0.375, Test loss 1.105\n",
      "Ep 2 (Step: 000155): Train loss 0.388, Test loss 1.133\n",
      "Ep 2 (Step: 000160): Train loss 0.401, Test loss 1.097\n",
      "Ep 2 (Step: 000165): Train loss 0.438, Test loss 1.120\n",
      "Ep 2 (Step: 000170): Train loss 0.413, Test loss 1.075\n",
      "Ep 2 (Step: 000175): Train loss 0.391, Test loss 1.118\n",
      "Ep 2 (Step: 000180): Train loss 0.463, Test loss 1.128\n",
      "Ep 2 (Step: 000185): Train loss 0.378, Test loss 1.150\n",
      "Ep 2 (Step: 000190): Train loss 0.386, Test loss 1.084\n",
      "Ep 2 (Step: 000195): Train loss 0.334, Test loss 1.128\n",
      "Ep 2 (Step: 000200): Train loss 0.370, Test loss 1.146\n",
      "Ep 2 (Step: 000205): Train loss 0.387, Test loss 1.089\n",
      "Ep 2 (Step: 000210): Train loss 0.366, Test loss 1.105\n",
      "Ep 2 (Step: 000215): Train loss 0.390, Test loss 1.115\n",
      "Ep 2 (Step: 000220): Train loss 0.369, Test loss 1.065\n",
      "Ep 2 (Step: 000225): Train loss 0.331, Test loss 1.128\n",
      "Ep 2 (Step: 000230): Train loss 0.372, Test loss 1.088\n",
      "decoded text:  Below is an instruction that describe a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The correct spelling is 'Occasion.'<|endoftext|>The following is an instruction that describe a task. Write a response that appropriately completes the request.  ### Response: The correct spelling is 'Occasion.'<|endoftext|>The\n",
      "Training completed in 27.02 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    gpt.parameters(),\n",
    "    lr=0.00005,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "\n",
    "num_epocs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    gpt, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epocs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_alpa_input(val_d[0]),tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
